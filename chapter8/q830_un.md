• the cache is 8 KiB in size and 2-way set associative and has a block size of 64 bytes;  
• the cache has a write-hit policy of write back, a write-miss policy of write allocate, and a replacement policy of LRU;  
• the cache is initially empty;  
• an object of type float requires 4 bytes of storage (i.e., sizeof(float) is 4);  
• the array a is aligned on a 4096-byte boundary;  
• the arrays a, b, and c are stored contiguously in memory in that order (with no padding between them);  
• the variables i and j are kept in registers for the duration of the code fragment execution, so that accesses to these variables do not impact caching;  
• while the code fragment is executing, no other code executes;  
• the compiler does not apply any code transformations (e.g., optimizations) that would change the order of memory accesses from what is shown in the source listing.  
```C++
constexpr int n = 2048;
float a[4][n];
float b[4][n];
float c[4][n];

int main(int argc, char const *argv[])
{
  for (int i = 0; i < n; ++i) {
    for (int j = 0; j < 4; ++j) {
      c[j][i] = a[j][i] + b[j][i];
    }
  }
  return 0;
}
```

## Scenario a: n = 2048
Size of Total RAM = 98304B  
Size of Cache = 8192B  
Size of Block = 64B  
Number of Blocks in a Set = 2  
Number of Sets = 64  

Therefore, we have 98304/64 = 12 blocks of RAM that are mapped to 1 set in the cache.

There are 8192 cycles in the program. Each cycle of the code involes 3 steps: 2 reads(denote as read A and read B) and 1 write. When 1st read A happens, it's a read miss and loads 1 block to cache. 1 block can hold 16 floats, so the next 15 read A will be read hit. From the 17th read A, it's 1 read miss, 1 load fram RAM and 15 read hit again. In the next block, LRU policy will take effect. The first 16 floats in the 2-way set will be discarded, and it will still be 1 read miss and 15 read hit. Same goes for all the datas in array a and array b. So in the reading process of array a and b, there are a total of 1024 cache miss and 15360 cache hit.

For the write processes, in the 1st write it will be a write miss. Because of write allocate policy, 1 block will be loaded to cache and followed by a write back. The next 15 writes will be write hit. Write to the next block will also be 1 write miss and 15 write hit. When writing to the 3rd block, the 1st block will be evicted and written to memory.

In conclusion, the cache miss rate is constant at 1/16 = 6.25%

## Scenario a: n = 2064